# -*- coding: utf-8 -*-
"""APS360_Group29_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Udz1-XCfVaWxYDtSx-yC7A-t5TyWvEa7
"""

import numpy as np
import time
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision
from torch.utils.data.sampler import SubsetRandomSampler
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import os
import torchvision.models

"""### Data Processing/Visualization"""

#mount googledrive
from google.colab import drive
drive.mount('/content/gdrive')

# location on Google Drive
master_path = '/content/gdrive/MyDrive/APS360 Project/Data'

# Transform Settings - Do not use RandomResizedCrop
transform = transforms.Compose([transforms.Resize((224,224)),
                                transforms.Grayscale(3),
                                transforms.ToTensor()])

# Load data from Google Drive
sample_dataset = torchvision.datasets.ImageFolder(master_path, transform=transform)

# Prepare Dataloader
batch_size = 32
num_workers = 1
sample_data_loader = torch.utils.data.DataLoader(sample_dataset, batch_size=batch_size,
                                           num_workers=num_workers, shuffle=True)

# Verification Step - obtain one batch of images
dataiter = iter(sample_data_loader)
images, labels = next(dataiter)
images = images.numpy() # convert images to numpy for display

classes = ['Forge', 'Real']

# plot the images in the batch, along with the corresponding labels
fig = plt.figure(figsize=(25, 4))
for idx in np.arange(20):
    ax = fig.add_subplot(2, 10, idx+1, xticks=[], yticks=[])
    plt.imshow(np.transpose(images[idx], (1, 2, 0)))
    ax.set_title(classes[labels[idx]])

pip install split-folders[full]

!pip install torchsummary

import splitfolders
input_folder = '/content/gdrive/MyDrive/APS360 Project/Data/'
splitfolders.ratio(input_folder, output="dataset", seed = 42, ratio= (.6,.3,.1), group_prefix=None)

train_path = '/content/dataset/train'
valid_path = '/content/dataset/val'
test_path = '/content/dataset/test'

# Transform Settings - Do not use RandomResizedCrop
transform = transforms.Compose([transforms.Resize((224,224)),
                                transforms.Grayscale(3),
                                transforms.ToTensor()])

trainset = torchvision.datasets.ImageFolder(train_path, transform=transform)
validset = torchvision.datasets.ImageFolder(valid_path, transform=transform)
testset = torchvision.datasets.ImageFolder(test_path, transform=transform)

# print out some data stats
print('Num training images: ', len(trainset))
print('Num validation images: ', len(validset))
print('Num testing images：', len(testset))

batch_size = 32
num_workers = 1
batch_small = 27
train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,num_workers=num_workers, shuffle=True)
valid_loader = torch.utils.data.DataLoader(validset, batch_size=batch_size,num_workers=num_workers, shuffle=True)
test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size,num_workers=num_workers, shuffle=True)

classes = ['Forge', 'Real']

"""◦The choice of architecture makes sense for the problem.

◦The architecture implementation is based on neural networks.

◦Visual elements are professional, concise and easy to read.

◦The best results achieved with your model in terms of quantitative (i.e., accuracy, error, loss) and
qualitative (i.e., identify something interesting about how your model performs on select samples
or class of samples).

◦Describe any challenges you may have faced with the task.

### CNN model

Convolutional Neural Networks (CNNs) have been extensively used for image classification tasks. CNNs can be particularly helpful for analyzing signature images and extracting features that can be used to distinguish between authentic and forged signatures in the context of signature authentication.

The ability of CNNs to learn to recognize features at various levels of abstraction is one of their benefits. Edges and corners are examples of low-level features that can be recognized by the initial layers of a CNN, whereas curves and loops are examples of more complex features that can be recognized by the deeper layers. These characteristics might be found in signature images in the form of the signature's shape, the force and swiftness of the penstrokes, or the distance between the letters.

The capacity of CNNs to learn from sizable datasets is another benefit. A large number of real and fake signatures are typically needed to train the model in signature authentication systems. The accuracy of CNNs can be increased by training them on millions of signature images and allowing them to learn from a large amount of data.

CNNs are also made to handle image variations like rotation, translation, and scaling. Given that signatures can be written in various orientations and sizes, this is especially helpful for signature authentication. Despite these variations, CNNs are able to recognize the fundamental patterns and characteristics of the signature.

However, CNNs can find it difficult to generalize and recognize genuine signatures if there is a large variation in signature style or if met with superiorly forged signatures.
"""

class SignatureCNN(nn.Module):
    def __init__(self):
        super(SignatureCNN, self).__init__()
        self.name = "SignatureCNN"
        self.conv1 = nn.Conv2d(3, 5, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(5, 10, 5)
        self.conv3 = nn.Conv2d(10, 20, 5)
        self.conv4 = nn.Conv2d(20, 30, 5)
        self.pool2 = nn.MaxPool2d(2, 2)
        self.fc1 = nn.Linear(30 * 22 * 22, 64)
        self.fc2 = nn.Linear(64, 2)
        self.dropout = nn.Dropout(p=0.45)
        self.leakyrelu = nn.LeakyReLU()

    def forward(self, x):
        x = self.pool(self.leakyrelu(self.conv1(x)))
        x = self.pool(self.leakyrelu(self.conv2(x)))
        x = self.leakyrelu(self.conv3(x))
        x = self.pool2(self.leakyrelu(self.conv4(x)))
        x = x.view(-1, 30 * 22 * 22)
        x = self.leakyrelu(self.fc1(x))
        x = self.dropout(x)
        x = self.fc2(x)
        return x

"""### Training"""

use_cuda = True

def get_accuracy(model, batch_size, train=False):
    if train:
        data = trainset
    else:
        data = validset
    correct = 0
    total = 0
    for imgs, labels in torch.utils.data.DataLoader(data, batch_size=batch_size):


        #############################################
        # To Enable GPU Usage
        if use_cuda and torch.cuda.is_available():
          imgs = imgs.cuda()
          labels = labels.cuda()
        #############################################


        output = model(imgs)

        # Select index with maximum prediction score
        pred = output.max(1, keepdim=True)[1]
        correct += pred.eq(labels.view_as(pred)).sum().item()
        total += imgs.shape[0]
    return correct / total

def train(model, data, batch_size=128, learning_rate=3e-5, num_epochs=50):
    train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)

    iters, losses, train_acc, val_acc = [], [], [], []

    # Training
    start_time = time.time()
    n = 0 # the number of iterations
    for epoch in range(num_epochs):
        for imgs, labels in iter(train_loader):


            #############################################
            # To Enable GPU Usage
            if use_cuda and torch.cuda.is_available():
              imgs = imgs.cuda()
              labels = labels.cuda()
            #############################################


            out = model(imgs)             # forward pass
            loss = criterion(out, labels) # compute the total loss
            loss.backward()               # backward pass (compute parameter updates)
            optimizer.step()              # make the updates for each parameter
            optimizer.zero_grad()         # a clean up step for PyTorch

            # Save the current training information
            iters.append(n)
            losses.append(float(loss)/batch_size)             # compute *average* loss
            n += 1
        train_acc.append(get_accuracy(model, batch_size=batch_size, train=True)) # compute training accuracy
        val_acc.append(get_accuracy(model, batch_size=batch_size, train=False))  # compute validation accuracy
        print(("Epoch {}: Train accuracy: {} ; "+"Validation accuracy: {}").format(
                epoch + 1,
                train_acc[-1],
                val_acc[-1]))
        # Save the current model (checkpoint) to a file
    end_time = time.time()
    diff = end_time - start_time
    print("Total time used: {:.2f} seconds".format(diff))

    # Plotting
    plt.title("Training Curve")
    plt.plot(iters, losses, label="Train")
    plt.xlabel("Iterations")
    plt.ylabel("Loss")
    plt.show()

    plt.title("Training Curve")
    plt.plot(range(1 ,num_epochs+1), train_acc, label="Train")
    plt.plot(range(1 ,num_epochs+1), val_acc, label="Validation")
    plt.xlabel("Epochs")
    plt.ylabel("Training Accuracy")
    plt.legend(loc='best')
    plt.show()

    print("Final Training Accuracy: {}".format(train_acc[-1]))
    print("Final Validation Accuracy: {}".format(val_acc[-1]))

use_cuda = True

model = SignatureCNN()
if use_cuda and torch.cuda.is_available():
  model.cuda()
  print('CUDA is available!  Training on GPU ...')
else:
  print('CUDA is not available.  Training on CPU ...')

train(model, trainset)

from torchsummary import summary
summary(model, (3, 224, 224))

!pip install torchviz
from torchviz import make_dot

use_cuda = True

model = SignatureCNN()
if use_cuda and torch.cuda.is_available():
  model.cuda()
  print('CUDA is available!  Training on GPU ...')
else:
  print('CUDA is not available.  Training on CPU ...')

x = torch.randn(1,3,224,224)
if use_cuda and torch.cuda.is_available():
  x = x.cuda()

y = model(x)
dot = make_dot(y, params=dict(model.named_parameters()))
dot.render(filename='signaturecnn', format='pdf')

from sklearn.metrics import confusion_matrix
import torch

# Set the device to be used for prediction
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# Set the model to evaluation mode
model.eval()

# Initialize empty lists to store predictions and ground truth labels
predictions = []
labels = []

# Make predictions on the test data
with torch.no_grad():
    for images, targets in test_loader:
        images, targets = images.to(device), targets.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        predictions += predicted.tolist()
        labels += targets.tolist()

# Generate a confusion matrix using scikit-learn
confusion_mat = confusion_matrix(labels, predictions)

print("Confusion matrix:")
print(confusion_mat)

def get_test_accuracy(model, batch_size):
    data = testset
    correct = 0
    total = 0
    for imgs, labels in torch.utils.data.DataLoader(data, batch_size=batch_size):


        #############################################
        # To Enable GPU Usage
        if use_cuda and torch.cuda.is_available():
          imgs = imgs.cuda()
          labels = labels.cuda()
        #############################################


        output = model(imgs)

        # Select index with maximum prediction score
        pred = output.max(1, keepdim=True)[1]
        correct += pred.eq(labels.view_as(pred)).sum().item()
        total += imgs.shape[0]
    return correct / total

test_acc = get_test_accuracy(model, batch_size=128)
print("The testing accuracy of the best model is: ", test_acc)

from torch.nn.functional import softmax

# Select some images from the test set
dataiter = iter(valid_loader)
images, labels = next(iter(valid_loader))

# Move the images and labels to the GPU if available
if use_cuda and torch.cuda.is_available():
    images = images.cuda()
    labels = labels.cuda()

# Generate predictions for the images using the trained model
outputs = model(images)

# Apply softmax to the outputs to get the predicted probabilities
probs = softmax(outputs, dim=1)

# Convert the outputs, labels, and probabilities to numpy arrays for display
preds = np.argmax(outputs.detach().cpu().numpy(), axis=1)
labels = labels.cpu().numpy()
probs = probs.detach().cpu().numpy()

# Define the class names for your dataset
classes = ['Forge', 'Real']

# Plot the images and their predictions
fig = plt.figure(figsize=(25, 4))
for idx in np.arange(20):
    ax = fig.add_subplot(2, 10, idx+1, xticks=[], yticks=[])
    plt.imshow(np.transpose(images[idx].cpu().numpy(), (1, 2, 0)))
    ax.set_title("{} ({:.2f})".format(classes[preds[idx]], probs[idx, preds[idx]]),
                 color=("green" if preds[idx]==labels[idx] else "red"))

plt.show()

# Select an image from the test set
dataiter = iter(test_loader)
images, labels = next(iter(test_loader))
image = images[0]

# Move the image to the GPU if available
if use_cuda and torch.cuda.is_available():
    image = image.cuda()

# Define a function to plot the activations of a given layer
def plot_activations(layer, image):
    model.eval()
    activations = []
    def hook(module, input, output):
        activations.append(output.detach().cpu().numpy())
    handle = layer.register_forward_hook(hook)
    with torch.no_grad():
        model(image.unsqueeze(0))
    handle.remove()
    activations = activations[0]
    fig = plt.figure(figsize=(20, 10))
    for i in range(activations.shape[1]):
        ax = fig.add_subplot(4, 8, i+1)
        plt.imshow(activations[0, i])
        ax.axis('off')
    plt.show()

# Plot the activations of the first convolutional layer
plot_activations(model.conv1, image)

"""###Baseline model : KNN Model

For a simple baseline model for handwriting recognition, a simple k-Nearest Neighbors (k-NN) classifier could be used. This is a non-parametric, instance-based machine learning algorithm that can be used for classification tasks.

"""

import cv2
import numpy as np

def load_data(path):
    X, y = [], []
    for label, folder in enumerate(['Forge', 'Real']):
        for file in os.listdir(os.path.join(path, folder)):
            image = cv2.imread(os.path.join(path, folder, file), cv2.IMREAD_GRAYSCALE)
            image = cv2.resize(image, (256, 256)) / 255.0 # normalize between 0 and 1
            X.append(image.flatten())
            y.append(label)
    return np.array(X), np.array(y)

X, y = load_data('/content/gdrive/MyDrive/APS360 Project/Data/Train/')

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

k = 5 # number of neighbors
clf = KNeighborsClassifier(n_neighbors=k)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Predict on test data
y_pred = clf.predict(X_test)

# Compute confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Plot confusion matrix as heatmap
sns.heatmap(cm, annot=True, cmap='Blues')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()

"""### Hyperparameter Tuning"""

## Should we use the current CNN model to tune the parameters? Or are we using
## the updated (more complicated) model? I didn't run the code just in case.


# We found a sign of underfitting from the recent model, and we would like to
# change the parameter to prevent such problem.

def train(model, data, batch_size, learning_rate, num_epochs):
    train_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)

    iters, losses, train_acc, val_acc = [], [], [], []

    # Training
    start_time = time.time()
    n = 0 # the number of iterations
    for epoch in range(num_epochs):
        for imgs, labels in iter(train_loader):


            #############################################
            # To Enable GPU Usage
            if use_cuda and torch.cuda.is_available():
              imgs = imgs.cuda()
              labels = labels.cuda()
            #############################################


            out = model(imgs)             # forward pass
            loss = criterion(out, labels) # compute the total loss
            loss.backward()               # backward pass (compute parameter updates)
            optimizer.step()              # make the updates for each parameter
            optimizer.zero_grad()         # a clean up step for PyTorch

            # Save the current training information
            iters.append(n)
            losses.append(float(loss)/batch_size)             # compute *average* loss
            n += 1

        train_acc.append(get_accuracy(model, batch_size=batch_size, train=True)) # compute training accuracy
        val_acc.append(get_accuracy(model, batch_size=batch_size, train=False))  # compute validation accuracy

    # Save the current model (checkpoint) to a file
    end_time = time.time()
    diff = end_time - start_time
    print("Total time used: {:.2f} seconds".format(diff))

    print("Final Training Accuracy: {}".format(train_acc[-1]))
    print("Final Validation Accuracy: {}".format(val_acc[-1]))

"""Batch Size"""

batch_sizes = [16, 32, 64]

for size in batch_sizes:
  print(f"Batch Size = {size}:")
  train(model, trainset, size, 4e-4, 20)

"""Learning Rate"""

learning_rate = [4e-5, 4e-4, 4e-3, 4e-2]
for rate in learning_rates:
  print(f"Batch Size = {rate}:")
  train(model, trainset, 32, rate, 20)

"""Number of Epochs"""

num_epochs = [20, 25, 30]
for num in num_epochs:
  print(f"Batch Size = {num}:")
  train(model, trainset, 32, 4e-4, num)

"""###Live Demo"""

# location on Google Drive
master_path2 = '/content/gdrive/MyDrive/Demo/'

# Transform Settings - Do not use RandomResizedCrop
transform = transforms.Compose([transforms.Resize((224,224)),
                                transforms.Grayscale(3),
                                transforms.ToTensor()])

# Load data from Google Drive
sample_dataset = torchvision.datasets.ImageFolder(master_path2, transform=transform)

# Prepare Dataloader
batch_size = 32
num_workers = 1
sample_data_loader = torch.utils.data.DataLoader(sample_dataset, batch_size=batch_size,
                                           num_workers=num_workers, shuffle=True)

# Verification Step - obtain one batch of images
dataiter = iter(sample_data_loader)
images, labels = next(dataiter)
images = images.numpy() # convert images to numpy for display

classes = ['Forge', 'Real']

#prepare dataset for evaluation
data_path = '/content/gdrive/MyDrive/Demo/'
dataset = torchvision.datasets.ImageFolder(data_path, transform=transform)

# plot the images in the batch, along with the corresponding labels
fig = plt.figure(figsize=(25, 4))
for idx in np.arange(10):
    ax = fig.add_subplot(2, 10, idx+1, xticks=[], yticks=[])
    plt.imshow(np.transpose(images[idx], (1, 2, 0)))
    ax.set_title(classes[labels[idx]])

from PIL import Image

# Load the image
img_path = 'DemoSuzie.jpg'
img = Image.open(img_path)
img2_path = 'RealSuzie.jpg'
img2 = Image.open(img2_path)
# Display the image
plt.imshow(img)
plt.axis('off')
plt.show()

# Display the image
plt.imshow(img2)
plt.axis('off')
plt.show()

# Preprocess the image
transform = transforms.Compose([transforms.Resize((224,224)),
                                transforms.Grayscale(3),
                                transforms.ToTensor()])
img = transform(img)

# Add an extra dimension to the tensor to represent the batch size
img = img.unsqueeze(0)

# Pass the image through the model
if use_cuda and torch.cuda.is_available():
    img = img.cuda()
    output = model(img)
    output = output.cpu()
else:
    output = model(img)

# Visualize the output of the first convolutional layer
weights = model.conv1.weight.detach().cpu()
grid = torchvision.utils.make_grid(weights, nrow=5, normalize=True, padding=2)
plt.imshow(grid.permute(1, 2, 0))
plt.axis('off')
plt.show()

# Define a new model that outputs the feature maps of the first convolutional layer
class FeatureExtractor(nn.Module):
    def __init__(self, model):
        super(FeatureExtractor, self).__init__()
        self.features = nn.Sequential(*list(model.children())[:4])

    def forward(self, x):
        x = self.features(x)
        return x

# Create an instance of the FeatureExtractor model
extractor = FeatureExtractor(model)

# Extract the output of the first convolutional layer for the input image
with torch.no_grad():
    conv1_output = extractor(img.cuda())

# Plot the feature maps as grayscale images
fig = plt.figure(figsize=(16, 8))
for i in range(conv1_output.shape[1]):
    ax = fig.add_subplot(4, 8, i+1, xticks=[], yticks=[])
    ax.imshow(conv1_output[0, i].cpu(), cmap='gray')
    ax.set_title(f'Feature map {i+1}')

# Pass the image through the model
if use_cuda and torch.cuda.is_available():
    img = img.cuda()
    output = model(img)
    output = output.cpu()
else:
    output = model(img)

# Visualize the output of the model
pred = output.max(1, keepdim=True)[1]
fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=1, nrows=2)
ax1.imshow(img.squeeze(0).permute(1, 2, 0).detach().cpu())
ax1.set_title('Input Image')
ax1.axis('off')
ax2.bar(classes, F.softmax(output, dim=1).detach().cpu().squeeze().numpy())
ax2.set_title('Class Probability')
plt.tight_layout()
plt.show()

def get_test_accuracy(model, batch_size):
    data = testset
    correct = 0
    total = 0
    for imgs, labels in torch.utils.data.DataLoader(data, batch_size=batch_size):


        #############################################
        # To Enable GPU Usage
        if use_cuda and torch.cuda.is_available():
          imgs = imgs.cuda()
          labels = labels.cuda()
        #############################################


        output = model(imgs)

        # Select index with maximum prediction score
        pred = output.max(1, keepdim=True)[1]
        correct += pred.eq(labels.view_as(pred)).sum().item()
        total += imgs.shape[0]
    return correct / total

test_acc = get_test_accuracy(model, batch_size=32)
print("The testing accuracy of the model is: ", test_acc)
